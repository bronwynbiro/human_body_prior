{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pose forecasting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FZE4PUNfAdj"
      },
      "source": [
        "# Data preparation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lmEoZUy6AT_"
      },
      "source": [
        "Install and import the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehCVv9zc5w8X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7d480a3-a64e-4ae1-fe8a-335ac0902708"
      },
      "source": [
        "!pip install smplx\n",
        "!pip install git+https://github.com/nghorbani/configer\n",
        "!pip install trimesh\n",
        "!pip install pyrender"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting smplx\n",
            "  Downloading https://files.pythonhosted.org/packages/20/51/cd68a91ce99e9fa958128eb76d8ae4759124cd7326aa9e745d7e13b4e3bd/smplx-0.1.26-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from smplx) (1.19.5)\n",
            "Collecting torchgeometry>=0.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/d6/3f6820c0589bc3876080c59b58a3bad11af746a7b46f364b1cde7972bd72/torchgeometry-0.1.2-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.1.post2 in /usr/local/lib/python3.7/dist-packages (from smplx) (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.1.post2->smplx) (3.7.4.3)\n",
            "Installing collected packages: torchgeometry, smplx\n",
            "Successfully installed smplx-0.1.26 torchgeometry-0.1.2\n",
            "Collecting git+https://github.com/nghorbani/configer\n",
            "  Cloning https://github.com/nghorbani/configer to /tmp/pip-req-build-oyjgn0ca\n",
            "  Running command git clone -q https://github.com/nghorbani/configer /tmp/pip-req-build-oyjgn0ca\n",
            "Collecting configparser\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Building wheels for collected packages: configer\n",
            "  Building wheel for configer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configer: filename=configer-1.4.1-cp37-none-any.whl size=7848 sha256=0250d8fc0c59e16e0a1a435b613e771c724663b06ba283b17716bd53884a1006\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ucpbqtua/wheels/4a/5d/ef/47b4fb4b0c90f8049bf1fe0d52cc9d89a36b90465561a3c015\n",
            "Successfully built configer\n",
            "Installing collected packages: configparser, configer\n",
            "Successfully installed configer-1.4.1 configparser-5.0.2\n",
            "Collecting trimesh\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/1d/2bb87a294a7c090130f8648c645dee038739cd03efc0f6e73c5bba47af20/trimesh-3.9.15-py3-none-any.whl (632kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from trimesh) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from trimesh) (56.0.0)\n",
            "Installing collected packages: trimesh\n",
            "Successfully installed trimesh-3.9.15\n",
            "Collecting pyrender\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/88/174c28b9d3d03cf6d8edb6f637458f30f1cf1a2bd7a617cbd9dadb1740f6/pyrender-0.1.45-py3-none-any.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pyrender) (1.15.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from pyrender) (2.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyrender) (1.4.1)\n",
            "Collecting freetype-py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/b5/56751e13f8b4a42f52c1b85ecce1446f83245190d820b42748eb8574ae43/freetype_py-2.2.0-py3-none-manylinux1_x86_64.whl (890kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 20.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pyrender) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyrender) (1.19.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pyrender) (2.5.1)\n",
            "Requirement already satisfied: pyglet>=1.4.10 in /usr/local/lib/python3.7/dist-packages (from pyrender) (1.5.0)\n",
            "Requirement already satisfied: trimesh in /usr/local/lib/python3.7/dist-packages (from pyrender) (3.9.15)\n",
            "Collecting PyOpenGL==3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/1d/4544708aaa89f26c97cc09450bb333a23724a320923e74d73e028b3560f9/PyOpenGL-3.1.0.tar.gz (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 31.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->pyrender) (4.4.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet>=1.4.10->pyrender) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from trimesh->pyrender) (56.0.0)\n",
            "Building wheels for collected packages: PyOpenGL\n",
            "  Building wheel for PyOpenGL (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyOpenGL: filename=PyOpenGL-3.1.0-cp37-none-any.whl size=1745211 sha256=54bc050012e3f2f8ed4bd24353261c07b3a924db0f2964f3a13417d182575fb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/00/7f/1dd736f380848720ad79a1a1de5272e0d3f79c15a42968fb58\n",
            "Successfully built PyOpenGL\n",
            "Installing collected packages: freetype-py, PyOpenGL, pyrender\n",
            "  Found existing installation: PyOpenGL 3.1.5\n",
            "    Uninstalling PyOpenGL-3.1.5:\n",
            "      Successfully uninstalled PyOpenGL-3.1.5\n",
            "Successfully installed PyOpenGL-3.1.0 freetype-py-2.2.0 pyrender-0.1.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gNfQAaFagai",
        "outputId": "74617fe0-ade9-4cd8-afbf-07bd8efbf5a7"
      },
      "source": [
        "!git clone https://github.com/bronwynbiro/human_body_prior"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'human_body_prior'...\n",
            "remote: Enumerating objects: 901, done.\u001b[K\n",
            "remote: Counting objects: 100% (202/202), done.\u001b[K\n",
            "remote: Compressing objects: 100% (179/179), done.\u001b[K\n",
            "remote: Total 901 (delta 100), reused 101 (delta 20), pack-reused 699\u001b[K\n",
            "Receiving objects: 100% (901/901), 25.68 MiB | 28.65 MiB/s, done.\n",
            "Resolving deltas: 100% (519/519), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4edolB6aQCX"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn9-XzlfYSh5",
        "outputId": "31df509e-5a64-4c71-a5d4-8eebb5f5ad2d"
      },
      "source": [
        "%cd human_body_prior/human_body_prior/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/human_body_prior/human_body_prior\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCXEydqV1iNO"
      },
      "source": [
        "We create a new file from the experiment data. There are features for the experiment number and frame number, and for each frame in each experiment we provide the values for the 72 SMPL body pose parameters. \n",
        "\n",
        "The code can be generated [here](https://github.com/bronwynbiro/human_body_prior/blob/master/generate_csv.py), or you can download the pkl.csv file from [here](https://drive.google.com/file/d/1KsapE49zsnLTI-gwj7rEUBgJ871Lx6Xl/view?usp=sharing) (recommended). Place it in the `human_body_prior/data` file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "VUGcChaIY6Gx",
        "outputId": "3b74d05a-0ce2-4907-824c-bbe62924a768"
      },
      "source": [
        "df = pd.read_csv('data/pkl.csv')  \n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>experiment_num</th>\n",
              "      <th>frame_num</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.866536</td>\n",
              "      <td>0.075659</td>\n",
              "      <td>-1.145443</td>\n",
              "      <td>0.050882</td>\n",
              "      <td>-0.070009</td>\n",
              "      <td>0.026480</td>\n",
              "      <td>-0.074817</td>\n",
              "      <td>-0.001138</td>\n",
              "      <td>-0.017932</td>\n",
              "      <td>0.196515</td>\n",
              "      <td>0.049918</td>\n",
              "      <td>-0.024497</td>\n",
              "      <td>0.109902</td>\n",
              "      <td>-0.142839</td>\n",
              "      <td>-0.052636</td>\n",
              "      <td>0.351383</td>\n",
              "      <td>-0.082448</td>\n",
              "      <td>0.018162</td>\n",
              "      <td>0.057499</td>\n",
              "      <td>0.005253</td>\n",
              "      <td>-0.021140</td>\n",
              "      <td>-0.232680</td>\n",
              "      <td>0.123407</td>\n",
              "      <td>0.017125</td>\n",
              "      <td>-0.186094</td>\n",
              "      <td>-0.062421</td>\n",
              "      <td>-0.007275</td>\n",
              "      <td>0.077147</td>\n",
              "      <td>0.049321</td>\n",
              "      <td>-0.007620</td>\n",
              "      <td>-0.055069</td>\n",
              "      <td>0.068586</td>\n",
              "      <td>0.030873</td>\n",
              "      <td>-0.018599</td>\n",
              "      <td>0.033485</td>\n",
              "      <td>0.073937</td>\n",
              "      <td>0.083949</td>\n",
              "      <td>0.170684</td>\n",
              "      <td>0.005117</td>\n",
              "      <td>0.022195</td>\n",
              "      <td>0.061079</td>\n",
              "      <td>-0.381387</td>\n",
              "      <td>-0.016794</td>\n",
              "      <td>0.129674</td>\n",
              "      <td>0.406932</td>\n",
              "      <td>0.281262</td>\n",
              "      <td>-0.006526</td>\n",
              "      <td>-0.015036</td>\n",
              "      <td>0.146671</td>\n",
              "      <td>-0.161312</td>\n",
              "      <td>-0.896686</td>\n",
              "      <td>0.213676</td>\n",
              "      <td>0.438120</td>\n",
              "      <td>0.810122</td>\n",
              "      <td>0.327218</td>\n",
              "      <td>-1.556438</td>\n",
              "      <td>0.502480</td>\n",
              "      <td>0.385893</td>\n",
              "      <td>1.373885</td>\n",
              "      <td>-0.511340</td>\n",
              "      <td>0.054412</td>\n",
              "      <td>-0.121351</td>\n",
              "      <td>0.130947</td>\n",
              "      <td>-0.063638</td>\n",
              "      <td>0.153678</td>\n",
              "      <td>-0.198115</td>\n",
              "      <td>-0.033524</td>\n",
              "      <td>0.009195</td>\n",
              "      <td>-0.369428</td>\n",
              "      <td>-0.047161</td>\n",
              "      <td>-0.019448</td>\n",
              "      <td>0.321557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-2.838369</td>\n",
              "      <td>0.075735</td>\n",
              "      <td>-1.143715</td>\n",
              "      <td>0.040607</td>\n",
              "      <td>-0.067597</td>\n",
              "      <td>0.050557</td>\n",
              "      <td>-0.025319</td>\n",
              "      <td>-0.007044</td>\n",
              "      <td>-0.014076</td>\n",
              "      <td>0.192631</td>\n",
              "      <td>0.055741</td>\n",
              "      <td>-0.026506</td>\n",
              "      <td>0.117011</td>\n",
              "      <td>-0.140747</td>\n",
              "      <td>-0.054009</td>\n",
              "      <td>0.252279</td>\n",
              "      <td>-0.072263</td>\n",
              "      <td>0.007663</td>\n",
              "      <td>0.061674</td>\n",
              "      <td>0.001663</td>\n",
              "      <td>-0.025815</td>\n",
              "      <td>-0.238407</td>\n",
              "      <td>0.126472</td>\n",
              "      <td>0.011188</td>\n",
              "      <td>-0.193134</td>\n",
              "      <td>-0.060448</td>\n",
              "      <td>-0.014639</td>\n",
              "      <td>0.077598</td>\n",
              "      <td>0.051748</td>\n",
              "      <td>-0.007666</td>\n",
              "      <td>-0.055225</td>\n",
              "      <td>0.067399</td>\n",
              "      <td>0.033278</td>\n",
              "      <td>-0.019427</td>\n",
              "      <td>0.031957</td>\n",
              "      <td>0.077390</td>\n",
              "      <td>0.070754</td>\n",
              "      <td>0.190760</td>\n",
              "      <td>-0.014085</td>\n",
              "      <td>0.019257</td>\n",
              "      <td>0.068265</td>\n",
              "      <td>-0.385795</td>\n",
              "      <td>-0.013156</td>\n",
              "      <td>0.116901</td>\n",
              "      <td>0.414061</td>\n",
              "      <td>0.293120</td>\n",
              "      <td>0.011190</td>\n",
              "      <td>-0.022356</td>\n",
              "      <td>0.146521</td>\n",
              "      <td>-0.162157</td>\n",
              "      <td>-0.899592</td>\n",
              "      <td>0.216117</td>\n",
              "      <td>0.450869</td>\n",
              "      <td>0.819911</td>\n",
              "      <td>0.328563</td>\n",
              "      <td>-1.553030</td>\n",
              "      <td>0.505692</td>\n",
              "      <td>0.405574</td>\n",
              "      <td>1.333898</td>\n",
              "      <td>-0.486168</td>\n",
              "      <td>0.063756</td>\n",
              "      <td>-0.115439</td>\n",
              "      <td>0.134983</td>\n",
              "      <td>-0.059764</td>\n",
              "      <td>0.156251</td>\n",
              "      <td>-0.198110</td>\n",
              "      <td>-0.031229</td>\n",
              "      <td>0.004888</td>\n",
              "      <td>-0.363507</td>\n",
              "      <td>-0.047416</td>\n",
              "      <td>-0.019419</td>\n",
              "      <td>0.314796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.829223</td>\n",
              "      <td>0.090393</td>\n",
              "      <td>-1.148443</td>\n",
              "      <td>0.063496</td>\n",
              "      <td>-0.055999</td>\n",
              "      <td>0.065752</td>\n",
              "      <td>0.001324</td>\n",
              "      <td>-0.010209</td>\n",
              "      <td>-0.013241</td>\n",
              "      <td>0.173072</td>\n",
              "      <td>0.059233</td>\n",
              "      <td>-0.026757</td>\n",
              "      <td>0.064246</td>\n",
              "      <td>-0.153684</td>\n",
              "      <td>-0.042731</td>\n",
              "      <td>0.178812</td>\n",
              "      <td>-0.060165</td>\n",
              "      <td>-0.002129</td>\n",
              "      <td>0.061603</td>\n",
              "      <td>0.002669</td>\n",
              "      <td>-0.027728</td>\n",
              "      <td>-0.227414</td>\n",
              "      <td>0.133802</td>\n",
              "      <td>0.005039</td>\n",
              "      <td>-0.189296</td>\n",
              "      <td>-0.065465</td>\n",
              "      <td>-0.012650</td>\n",
              "      <td>0.090368</td>\n",
              "      <td>0.055797</td>\n",
              "      <td>-0.005831</td>\n",
              "      <td>-0.053037</td>\n",
              "      <td>0.064830</td>\n",
              "      <td>0.036626</td>\n",
              "      <td>-0.014236</td>\n",
              "      <td>0.031690</td>\n",
              "      <td>0.078841</td>\n",
              "      <td>0.124344</td>\n",
              "      <td>0.191155</td>\n",
              "      <td>-0.034091</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.087399</td>\n",
              "      <td>-0.348454</td>\n",
              "      <td>-0.009559</td>\n",
              "      <td>0.099641</td>\n",
              "      <td>0.391766</td>\n",
              "      <td>0.329253</td>\n",
              "      <td>0.007764</td>\n",
              "      <td>-0.022938</td>\n",
              "      <td>0.147610</td>\n",
              "      <td>-0.174609</td>\n",
              "      <td>-0.893082</td>\n",
              "      <td>0.219475</td>\n",
              "      <td>0.465768</td>\n",
              "      <td>0.821067</td>\n",
              "      <td>0.340594</td>\n",
              "      <td>-1.593601</td>\n",
              "      <td>0.498695</td>\n",
              "      <td>0.445730</td>\n",
              "      <td>1.374859</td>\n",
              "      <td>-0.460087</td>\n",
              "      <td>0.067147</td>\n",
              "      <td>-0.116501</td>\n",
              "      <td>0.143336</td>\n",
              "      <td>-0.075582</td>\n",
              "      <td>0.153389</td>\n",
              "      <td>-0.195452</td>\n",
              "      <td>-0.027182</td>\n",
              "      <td>0.011999</td>\n",
              "      <td>-0.359782</td>\n",
              "      <td>-0.046835</td>\n",
              "      <td>-0.026848</td>\n",
              "      <td>0.310718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>-2.825207</td>\n",
              "      <td>0.089673</td>\n",
              "      <td>-1.140104</td>\n",
              "      <td>0.072179</td>\n",
              "      <td>-0.063327</td>\n",
              "      <td>0.063198</td>\n",
              "      <td>0.019392</td>\n",
              "      <td>-0.015909</td>\n",
              "      <td>-0.011003</td>\n",
              "      <td>0.173403</td>\n",
              "      <td>0.065946</td>\n",
              "      <td>-0.026625</td>\n",
              "      <td>0.056366</td>\n",
              "      <td>-0.167516</td>\n",
              "      <td>-0.040978</td>\n",
              "      <td>0.181117</td>\n",
              "      <td>-0.056387</td>\n",
              "      <td>-0.000715</td>\n",
              "      <td>0.054548</td>\n",
              "      <td>0.009960</td>\n",
              "      <td>-0.028651</td>\n",
              "      <td>-0.231065</td>\n",
              "      <td>0.132051</td>\n",
              "      <td>0.002744</td>\n",
              "      <td>-0.201887</td>\n",
              "      <td>-0.065286</td>\n",
              "      <td>-0.011699</td>\n",
              "      <td>0.086380</td>\n",
              "      <td>0.064775</td>\n",
              "      <td>-0.005147</td>\n",
              "      <td>-0.061064</td>\n",
              "      <td>0.068311</td>\n",
              "      <td>0.038010</td>\n",
              "      <td>-0.023431</td>\n",
              "      <td>0.033477</td>\n",
              "      <td>0.076317</td>\n",
              "      <td>0.078042</td>\n",
              "      <td>0.198403</td>\n",
              "      <td>-0.018582</td>\n",
              "      <td>0.012670</td>\n",
              "      <td>0.091686</td>\n",
              "      <td>-0.342287</td>\n",
              "      <td>-0.012891</td>\n",
              "      <td>0.107499</td>\n",
              "      <td>0.381302</td>\n",
              "      <td>0.297573</td>\n",
              "      <td>0.013360</td>\n",
              "      <td>-0.017678</td>\n",
              "      <td>0.147299</td>\n",
              "      <td>-0.170567</td>\n",
              "      <td>-0.915190</td>\n",
              "      <td>0.212589</td>\n",
              "      <td>0.471162</td>\n",
              "      <td>0.831528</td>\n",
              "      <td>0.306601</td>\n",
              "      <td>-1.636701</td>\n",
              "      <td>0.534682</td>\n",
              "      <td>0.420950</td>\n",
              "      <td>1.412081</td>\n",
              "      <td>-0.505871</td>\n",
              "      <td>0.065309</td>\n",
              "      <td>-0.116460</td>\n",
              "      <td>0.141962</td>\n",
              "      <td>-0.075909</td>\n",
              "      <td>0.154490</td>\n",
              "      <td>-0.199943</td>\n",
              "      <td>-0.025886</td>\n",
              "      <td>0.007023</td>\n",
              "      <td>-0.359902</td>\n",
              "      <td>-0.045624</td>\n",
              "      <td>-0.022944</td>\n",
              "      <td>0.309714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>-2.877287</td>\n",
              "      <td>0.085534</td>\n",
              "      <td>-1.024322</td>\n",
              "      <td>0.117452</td>\n",
              "      <td>-0.058068</td>\n",
              "      <td>0.036590</td>\n",
              "      <td>-0.000754</td>\n",
              "      <td>-0.010078</td>\n",
              "      <td>-0.016400</td>\n",
              "      <td>0.164260</td>\n",
              "      <td>0.048183</td>\n",
              "      <td>-0.020332</td>\n",
              "      <td>0.043498</td>\n",
              "      <td>-0.181379</td>\n",
              "      <td>-0.042301</td>\n",
              "      <td>0.230787</td>\n",
              "      <td>-0.052373</td>\n",
              "      <td>-0.000683</td>\n",
              "      <td>0.051952</td>\n",
              "      <td>0.005621</td>\n",
              "      <td>-0.027468</td>\n",
              "      <td>-0.235382</td>\n",
              "      <td>0.136976</td>\n",
              "      <td>0.006767</td>\n",
              "      <td>-0.204834</td>\n",
              "      <td>-0.076237</td>\n",
              "      <td>0.000580</td>\n",
              "      <td>0.089965</td>\n",
              "      <td>0.053683</td>\n",
              "      <td>-0.008654</td>\n",
              "      <td>-0.084683</td>\n",
              "      <td>0.073989</td>\n",
              "      <td>0.035373</td>\n",
              "      <td>-0.043408</td>\n",
              "      <td>0.047037</td>\n",
              "      <td>0.064760</td>\n",
              "      <td>0.072398</td>\n",
              "      <td>0.217221</td>\n",
              "      <td>-0.014488</td>\n",
              "      <td>0.015751</td>\n",
              "      <td>0.096391</td>\n",
              "      <td>-0.343589</td>\n",
              "      <td>-0.017429</td>\n",
              "      <td>0.098780</td>\n",
              "      <td>0.373383</td>\n",
              "      <td>0.291016</td>\n",
              "      <td>0.015239</td>\n",
              "      <td>-0.035457</td>\n",
              "      <td>0.154262</td>\n",
              "      <td>-0.165363</td>\n",
              "      <td>-0.920355</td>\n",
              "      <td>0.233473</td>\n",
              "      <td>0.463017</td>\n",
              "      <td>0.845733</td>\n",
              "      <td>0.365914</td>\n",
              "      <td>-1.572845</td>\n",
              "      <td>0.481966</td>\n",
              "      <td>0.462682</td>\n",
              "      <td>1.424765</td>\n",
              "      <td>-0.483427</td>\n",
              "      <td>0.092077</td>\n",
              "      <td>-0.111556</td>\n",
              "      <td>0.139014</td>\n",
              "      <td>-0.055702</td>\n",
              "      <td>0.147208</td>\n",
              "      <td>-0.200182</td>\n",
              "      <td>-0.039764</td>\n",
              "      <td>0.007090</td>\n",
              "      <td>-0.350670</td>\n",
              "      <td>-0.052173</td>\n",
              "      <td>-0.019537</td>\n",
              "      <td>0.300950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   experiment_num  frame_num         1  ...        70        71        72\n",
              "0               0          0 -2.866536  ... -0.047161 -0.019448  0.321557\n",
              "1               0          1 -2.838369  ... -0.047416 -0.019419  0.314796\n",
              "2               0          2 -2.829223  ... -0.046835 -0.026848  0.310718\n",
              "3               0          3 -2.825207  ... -0.045624 -0.022944  0.309714\n",
              "4               0          4 -2.877287  ... -0.052173 -0.019537  0.300950\n",
              "\n",
              "[5 rows x 74 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qir3JxvVmdDy"
      },
      "source": [
        "As in SMPL-X [[1](https://github.com/nghorbani/human_body_prior), [2](https://arxiv.org/abs/1904.05866)], we use do not use the pelvis or hand effexors, leaving us with 21 joints to consider. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lbk2NZBZ3LY"
      },
      "source": [
        "# Reshape into (n, 3, 21), ie ignore the pelvis and hand effexors\n",
        "def reshape_vibe(arr):\n",
        "  arr = arr.reshape(-1, 3, 24)\n",
        "  n = arr.shape[0]\n",
        "  reshaped = np.zeros(shape=(n, 3, 21))\n",
        "  for i in range(n):\n",
        "    reshaped[i] = arr[i, :, 1:22]\n",
        "  \n",
        "  return reshaped"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9ARI4Mh4pCy"
      },
      "source": [
        "To generate the training and test datasets, select 10% from each experiment as start sequences for our test sequences. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91eLLbWsZJNR"
      },
      "source": [
        "def generate_datasets_for_training(data, timesteps_input, timesteps_output, sample_rate=0.1):\n",
        "  n = len(data) \n",
        "  X_train = []\n",
        "  X_test = []\n",
        "\n",
        "  Y_train = []\n",
        "  Y_test = []\n",
        "\n",
        "  for experiment_num in range(145):\n",
        "    # For each experiment, we generate sample_rate % to use as for testing\n",
        "    n = len(df.loc[df['experiment_num'] == experiment_num])\n",
        "    num_samples = int(sample_rate * n)\n",
        "    to_test = random.sample(range(0, n-timesteps_input), num_samples)\n",
        "\n",
        "    for i in range(0, n- timesteps_input-timesteps_output+1):\n",
        "      # Add start of sequence indices to test arrays\n",
        "      if i in to_test:\n",
        "        X_test.append(i)\n",
        "        Y_test.append(i)\n",
        "      \n",
        "      else:\n",
        "        X_train.append(data[i:i+timesteps_input][::-1])\n",
        "        Y_train.append(data[i+timesteps_input:i+timesteps_input+timesteps_output])\n",
        "\n",
        "  # Convert all into np arrays\n",
        "  X_train = np.asarray(X_train, dtype=float)\n",
        "  X_test = np.asarray(X_test, dtype=float)\n",
        "\n",
        "  Y_train = np.asarray(Y_train, dtype=float)\n",
        "  Y_test = np.asarray(Y_test, dtype=float)\n",
        "\n",
        "  return (X_train.shape[2], X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Zwh_FvtAu_w",
        "outputId": "3d7ef9ba-b38b-4142-cd76-98d16ececaa5"
      },
      "source": [
        "timesteps_input, timesteps_output = 6, 6 \n",
        "feats, X, Y, X_test, Y_test = generate_datasets_for_training(df, timesteps_input, timesteps_output)\n",
        "print(feats, X.shape, X_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "74 (56860, 6, 74) (6362,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXgXs16wfH_E"
      },
      "source": [
        "# LSTM VAE "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AjsdZc_u8SG"
      },
      "source": [
        "We develop a Long Short-Term Memory (LSTM) Variational Autoencoder to forecast future poses. It learns a latent representation of human pose and regularizes the distribution of the latent code to be a normal distribution. We can then predict future poses given an input sequence. We used the following tutorials and code samples as reference:\n",
        "\n",
        "[Keras tutorial](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)\n",
        "\n",
        "[Seq2Seq tutorial](https://machinelearningmastery.com/define-encoder-decoder-sequence-sequence-model-neural-machine-translation-keras/)\n",
        "\n",
        "[Github](https://github.com/keras-team/keras-io/blob/master/examples/nlp/lstm_seq2seq.py)\n",
        "\n",
        "[Stack overflow](https://stackoverflow.com/questions/63987125/keras-lstm-vae-variational-autoencoder-for-time-series-anamoly-detection)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPeCeFGOfOhL",
        "outputId": "31848ba2-143e-495f-9466-6636028b5e66"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from keras import optimizers\n",
        "\n",
        "n_sample = X.shape[0]\n",
        "latent_dim = 32\n",
        "features = X.shape[2]\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='loss', min_delta=0.001, patience=5, verbose=0, mode='auto',\n",
        "    baseline=None, restore_best_weights=True)\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_sigma = args\n",
        "    batch_size = tf.shape(z_mean)[0] \n",
        "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=1.)\n",
        "    return z_mean + K.exp(0.5 * z_log_sigma) * epsilon\n",
        "\n",
        "encoder_inputs = Input(shape=(None, features))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "#z_layer\n",
        "z_mean = Dense(latent_dim)(encoder_outputs)\n",
        "z_log_sigma = Dense(latent_dim)(encoder_outputs)\n",
        "z = Lambda(sampling)([z_mean, z_log_sigma])\n",
        "repeated_context = RepeatVector(6)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None, features))\n",
        "\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = TimeDistributed(Dense(features, activation=\"linear\")) #_x_decoded_mean\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "def vae_loss2(input_x, decoder1, z_log_sigma, z_mean):\n",
        "    \"\"\" Calculate loss = reconstruction loss + KL loss for each data in minibatch \"\"\"\n",
        "    recon = K.mean(K.square(decoder1 - input_x)) * timesteps_input\n",
        "    kl = -0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma))\n",
        "    return recon + (0.0001 * kl)\n",
        "\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.add_loss(vae_loss2(encoder_inputs, decoder_inputs, z_log_sigma, z_mean))\n",
        "\n",
        "optimizer = optimizers.Adam()#clipvalue=0.5, lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.001)\n",
        "model.compile(optimizer=optimizer, metrics=[\"mean_squared_error\"])\n",
        "\n",
        "model.fit([X, Y], Y, epochs=200, callbacks=[early_stop])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['lstm_1/lstm_cell_1/kernel:0', 'lstm_1/lstm_cell_1/recurrent_kernel:0', 'lstm_1/lstm_cell_1/bias:0', 'time_distributed/kernel:0', 'time_distributed/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['lstm_1/lstm_cell_1/kernel:0', 'lstm_1/lstm_cell_1/recurrent_kernel:0', 'lstm_1/lstm_cell_1/bias:0', 'time_distributed/kernel:0', 'time_distributed/bias:0'] when minimizing the loss.\n",
            "1777/1777 [==============================] - 11s 5ms/step - loss: 42.1858 - mean_squared_error: 109.9443\n",
            "Epoch 2/200\n",
            "1777/1777 [==============================] - 9s 5ms/step - loss: 49.9157 - mean_squared_error: 111.1624\n",
            "Epoch 3/200\n",
            "1777/1777 [==============================] - 9s 5ms/step - loss: 51.3721 - mean_squared_error: 111.9581\n",
            "Epoch 4/200\n",
            "1777/1777 [==============================] - 9s 5ms/step - loss: 46.0788 - mean_squared_error: 105.9060\n",
            "Epoch 5/200\n",
            "1777/1777 [==============================] - 9s 5ms/step - loss: 43.2570 - mean_squared_error: 112.5325\n",
            "Epoch 6/200\n",
            "1777/1777 [==============================] - 9s 5ms/step - loss: 50.6767 - mean_squared_error: 115.6782\n",
            "Epoch 7/200\n",
            "1777/1777 [==============================] - 9s 5ms/step - loss: 45.7288 - mean_squared_error: 112.2591\n",
            "Epoch 8/200\n",
            "1777/1777 [==============================] - 9s 5ms/step - loss: 45.0562 - mean_squared_error: 112.6768\n",
            "Epoch 9/200\n",
            "1777/1777 [==============================] - 9s 5ms/step - loss: 42.6984 - mean_squared_error: 109.7104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbd2f9e6bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QSKYPZL0Dfd"
      },
      "source": [
        "encoder_inputs = model.input[0]  # input_1\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_inputs = model.input[1]  # input_2\n",
        "decoder_state_input_h = Input(shape=(latent_dim,), name=\"input_3\")\n",
        "decoder_state_input_c = Input(shape=(latent_dim,), name=\"input_4\")\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_lstm = model.layers[3]\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h_dec, state_c_dec]\n",
        "decoder_dense = model.layers[4]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0GLlUQs5cha"
      },
      "source": [
        "The code below generates an output sequence for the input sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60-B4lUE0Ofl"
      },
      "source": [
        "def decode_sequence(input_seq, timesteps_input, timesteps_output):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, features))\n",
        "\n",
        "    # Start with the last frame of the input as the target\n",
        "    target_seq[0,0,:] = input_seq[0,timesteps_input-1,:]\n",
        "\n",
        "    decoded_pose = []\n",
        "    \n",
        "    for i in range(timesteps_input):\n",
        "        output_pose, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        decoded_pose.append(output_pose)\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq[0,0,:] = output_pose\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return np.array(decoded_pose)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht4xfqpD5mfQ"
      },
      "source": [
        "The code below generates an output sequence for the input sequence, but generates multiple samples for each frame and chooses the best one. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjU-DtRpAYe9"
      },
      "source": [
        "def decode_sequence_multisample(input_seq, timesteps_input, timesteps_output, num_samples):\n",
        "    best_pose = None\n",
        "    min_err = float(\"inf\")\n",
        "    for _ in range(num_samples):\n",
        "      states_value = []\n",
        "\n",
        "      # Get random sample from z\n",
        "      for i in range(2):\n",
        "        states_value.append(K.random_normal(shape=(1, latent_dim), mean=0., stddev=1.))\n",
        "\n",
        "      # Generate empty target sequence of length\n",
        "      target_seq = np.zeros((1, 1, features))\n",
        "      target_seq[0,0,:] = input_seq[0,timesteps_input-1,:]\n",
        "\n",
        "      decoded_pose = []\n",
        "      \n",
        "      # Get predicted sequence\n",
        "      for i in range(timesteps_input):\n",
        "          output_pose, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "          decoded_pose.append(output_pose)\n",
        "\n",
        "          # Update the target sequence\n",
        "          target_seq[0,0,:] = output_pose\n",
        "\n",
        "          # Update states\n",
        "          states_value = [h, c]\n",
        "\n",
        "      decoded_pose = np.array(decoded_pose)\n",
        "      joint_err_per_frame = []\n",
        "\n",
        "      # Get the MPJPE for the sequence\n",
        "      for time in range(timesteps_output):\n",
        "        poses, predicted_poses = input_seq[0, time, :], decoded_pose[time]\n",
        "        poses, predicted_poses = reshape_vibe(poses[2:]), reshape_vibe(predicted_poses[0, 0, 2:])\n",
        "        for dim in range(poses.shape[1]): # 3 dimensions (x, y, z)\n",
        "          for joint in range(poses.shape[-1]): # 21 joints\n",
        "            frame_err = abs(poses[0, dim, joint] - predicted_poses[0, dim, joint])\n",
        "            joint_err_per_frame.append(frame_err)\n",
        "      \n",
        "      # Return the best sequence\n",
        "      err = sum(joint_err_per_frame) / len(joint_err_per_frame)\n",
        "      if err < min_err:\n",
        "        min_err = err\n",
        "        best_pose = decoded_pose\n",
        "      \n",
        "    return best_pose"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63H6Tvj5fXlS"
      },
      "source": [
        "# Visualization\n",
        "\n",
        "Note: Must be run on GPU, otherwise you may get the error \"Invalid device ID\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXcxaFiQ9mW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81476189-17d5-4487-a0fb-25120c0332d6"
      },
      "source": [
        "# Select a random sample to visualize\n",
        "idx, start = 139, 180\n",
        "test_seq = df.loc[df['experiment_num'] == idx]\n",
        "\n",
        "test_seq = test_seq[start_time:start_time+timesteps_input]\n",
        "test_seq = test_seq.to_numpy()\n",
        "print(test_seq.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttgLmY_a9DN3"
      },
      "source": [
        "%cd ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAEtsbgZ1Bsr"
      },
      "source": [
        "Run the visualization on the test sequence. You may need to adjust the expr_dir and bm_path. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9u0hhYRIn-r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "50878ad2-aa55-4dcd-f4ca-402dfdf06f40"
      },
      "source": [
        "from human_body_prior.tools.visualization_tools import render_smpl_params\n",
        "from notebooks.notebook_tools import show_image\n",
        "from human_body_prior.tools.visualization_tools import imagearray2file\n",
        "from human_body_prior.body_model.body_model import BodyModel\n",
        "from human_body_prior.tools.model_loader import load_vposer\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import os\n",
        "os.environ['PYOPENGL_PLATFORM'] = 'egl'\n",
        "\n",
        "expr_dir = '../vposer_v1_0'\n",
        "bm_path =  'smpl/models/neutral.pkl' \n",
        "\n",
        "bm = BodyModel(bm_path=bm_path, batch_size=1, use_posedirs=True)\n",
        "vp, ps = load_vposer(expr_dir, vp_model='snapshot')\n",
        "\n",
        "\n",
        "for i in range(timesteps_input):\n",
        "  sample = reshape_vibe(test_seq[i, 2:]).reshape(-1, 63)\n",
        "  images = render_smpl_params(bm, sample).reshape(1,1,1,400,400,3)\n",
        "  img = imagearray2file(images, \"test_original.png\")\n",
        "  for j in range(len(img)):\n",
        "    show_image(np.array(img)[j])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-5a268c26ebc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mbm_path\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m'smpl/models/neutral.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBodyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbm_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbm_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_posedirs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mvp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vposer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvp_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'snapshot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/human_body_prior/human_body_prior/body_model/body_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, bm_path, params, num_betas, batch_size, v_template, num_dmpls, path_dmpl, num_expressions, use_posedirs, dtype)\u001b[0m\n\u001b[1;32m     66\u001b[0m           \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m           \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m           \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbm_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m               \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Unpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m               \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'smpl/models/neutral.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mreUapuh1JQ2"
      },
      "source": [
        "Run the visualization on the predicted sequence, using the best of 5 samples. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az4uAvRG-zl2"
      },
      "source": [
        "test_seq = df[start:start+timesteps_input].to_numpy()\n",
        "pred_seq = test_seq \n",
        "num_samples = 5\n",
        "pred_seq = pred_seq.reshape((1,) + pred_seq.shape)\n",
        "prediction = decode_sequence_multisample(pred_seq, timesteps_input, timesteps_output, num_samples)\n",
        "\n",
        "for i in range(len(prediction)):\n",
        "  predicted_body = prediction[i]\n",
        "  predicted_body = reshape_vibe(predicted_body[0,0,2:]).reshape(-1, 63)\n",
        "  images = render_smpl_params(bm, predicted_body).reshape(1,1,1,400,400,3)\n",
        "  img = imagearray2file(images, \"test_out.png\")\n",
        "  for j in range(len(img)):\n",
        "    show_image(np.array(img)[j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZig0EF5vIKZ"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "We use Mean Per Joint Position Error (MPJPE) in metres as our evaluation metric, which measures the Euclidean distance between our generated future poses and the ground truth future poses. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aYA5ONfEbpS"
      },
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "joint_err_per_frame = []\n",
        "\n",
        "print(\"Running on {} sequences.\".format(str(len(X_test))))\n",
        "for start in X_test:\n",
        "  # Get ground truth\n",
        "  start = int(start)\n",
        "  samples = df.iloc[start:start+timesteps_input].to_numpy()\n",
        "\n",
        "  for time in range(timesteps_output):\n",
        "    sample = samples\n",
        "    sample = sample.reshape((1,) + sample.shape)\n",
        "    decoded_pose = decode_sequence(sample, timesteps_input, timesteps_output)\n",
        "    \n",
        "    # To test using the best pose with multiple samples, uncomment below \n",
        "    #decoded_pose = decode_sequence_multisample(sample, timesteps_input, timesteps_output, 10)\n",
        "    poses, predicted_poses = sample[0,i,:], decoded_pose[time, 0, 0, 2:]\n",
        "    poses = reshape_vibe(poses[2:])\n",
        "    predicted_poses = reshape_vibe(predicted_poses)\n",
        "    for dim in range(poses.shape[1]): # 3 dimensions (x, y, z)\n",
        "      for joint in range(poses.shape[-1]): # 21 joints\n",
        "        frame_err = abs(poses[0, dim, joint] - predicted_poses[0, dim, joint])\n",
        "        joint_err_per_frame.append(frame_err)\n",
        "\n",
        "avg_frame = sum(joint_err_per_frame) / len(joint_err_per_frame)\n",
        "print(\"Joint error per frame:\", avg_frame)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}